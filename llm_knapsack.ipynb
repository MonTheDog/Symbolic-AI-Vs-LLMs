{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import re\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'c:\\\\Users\\\\paolo\\\\Desktop\\\\Symbolic-AI-Vs-LLMs\\\\utils.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"C:/Users/paolo/Desktop/Symbolic-AI-Vs-LLMs\"))\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNAPSACK_PROMPT_BASE_4O = \"\"\"\n",
    "You have a set of items. Each item has a weight and a value. You have a knapsack that has a maximum capacity. Your goal is to maximize the value of the items you carry in the knapsack without exceeding the maximum capacity (the subset you select should be that with the maximum total value which is less than or equal to the maximum capacity). In the answer, include a string with the reasoning you used to find the solution and a json string with the solution in the form specified below.\n",
    "\n",
    "Items: ###\n",
    "{}\n",
    "###\n",
    "\n",
    "MaximumCapacity: ###\n",
    "{}\n",
    "###\n",
    "\n",
    "Desired format: ###\n",
    "Reasoning: ....\n",
    "\n",
    "Solution: \n",
    "[\n",
    "    {{\n",
    "        \"Name\": \"....\",\n",
    "        \"Weight\": ...,\n",
    "        \"Value\": ...\n",
    "    }},\n",
    "    {{\n",
    "        \"Name\": \"....\",\n",
    "        \"Weight\": ...,\n",
    "        \"Value\": ...\n",
    "    }},\n",
    "    ....\n",
    "]\n",
    "###\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnapsackItemSchema(BaseModel):\n",
    "    name: str\n",
    "    weight: int\n",
    "    value: int\n",
    "\n",
    "class KnapsackOutputSchema(BaseModel):\n",
    "    reasoning: str\n",
    "    solution: list[KnapsackItemSchema]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsack_to_llm_adapter(prompt):\n",
    "    \"\"\"\n",
    "    Input: items of the instance of knapsack problem as defined in /utils.py\n",
    "    Output: prompt formatted with the items converted to a json string and the capacity\n",
    "    \"\"\"\n",
    "    instance = utils.get_knapsack_instance()\n",
    "    return prompt.format(json.dumps(instance[\"items\"]), instance[\"capacity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNAPSACK_4O_CONVERSATION = [\n",
    "    {\"role\": \"system\", \"content\": \"You have to solve the knapsack problem.\"},\n",
    "    {\"role\": \"user\", \"content\": knapsack_to_llm_adapter(KNAPSACK_PROMPT_BASE_4O)}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning='To solve the knapsack problem with a maximum capacity of 20, I will evaluate different combinations of items to maximize the total value without exceeding the weight limit. I will use a methodical approach to determine the optimal selection of items based on their value-to-weight ratio, ensuring the combined weight does not exceed 20. After testing various combinations, the selection of items that maximizes the total value while remaining within the weight constraint emerges clearly, which includes valuable items with relatively lower weights.' solution=[KnapsackItemSchema(name='Diamond Necklace', weight=2, value=1200), KnapsackItemSchema(name='First Edition Charizard Card', weight=1, value=1500), KnapsackItemSchema(name='Antique Clock', weight=5, value=1200), KnapsackItemSchema(name='Lightsaber Replica', weight=3, value=1200), KnapsackItemSchema(name='Wedding Crown', weight=3, value=2000), KnapsackItemSchema(name='Vault Key', weight=1, value=1000), KnapsackItemSchema(name='Rare Book', weight=2, value=500)]\n"
     ]
    }
   ],
   "source": [
    "client = utils.get_openai_client()\n",
    "response = utils.interrogate_4o(client, \"mini\", KNAPSACK_4O_CONVERSATION, KnapsackOutputSchema)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNAPSACK_PROMPT_BASE_O1 = \"\"\"\n",
    "You have a set of items. Each item has a weight and a value. You have a knapsack that has a maximum capacity. Your goal is to maximize the value of the items you carry in the knapsack without exceeding the maximum capacity. In the answer, include a json string with the solution in the form specified below. Include only the json string in the form below, without any additional information. \n",
    "\n",
    "Items: ###\n",
    "{}\n",
    "###\n",
    "\n",
    "MaximumCapacity: ###\n",
    "{}\n",
    "###\n",
    "\n",
    "Desired format: ###\n",
    "[\n",
    "    {{\n",
    "        \"Name\": \"....\",\n",
    "        \"Weight\": ...,\n",
    "        \"Value\": ...\n",
    "    }},\n",
    "    {{\n",
    "        \"Name\": \"....\",\n",
    "        \"Weight\": ...,\n",
    "        \"Value\": ...\n",
    "    }},\n",
    "]\n",
    "###\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNAPSACK_O1_CONVERSATION = [\n",
    "    {\"role\": \"user\", \"content\": knapsack_to_llm_adapter(KNAPSACK_PROMPT_BASE_O1)}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsack_checking_schema(response):\n",
    "    \"\"\"\n",
    "    Boolean function that checks if the response provided by a LLM without the response format feature adheres to the required schema.\n",
    "    Includes a pre-processing step where everything which is not contained in the square brackets is removed.\n",
    "    Such a pre-processing step has been derived from the observation that the LLM sometimes includes additional information in the response.\n",
    "    \n",
    "    If the check is successful, the function returns the response in the correct format.\n",
    "    Otherwise, it returns False.\n",
    "\n",
    "    Input: string response provided by the LLM\n",
    "    \"\"\"\n",
    "    match = re.search(r'(\\[.*\\])', response, re.DOTALL)  #  pre-processing step\n",
    "    if not match:\n",
    "        return False\n",
    "    response = match.group(1)\n",
    "    \n",
    "    try:\n",
    "        response = json.loads(response)\n",
    "    except:\n",
    "        return False\n",
    "    if not isinstance(response, list):\n",
    "        return False\n",
    "    \n",
    "    for item in response:\n",
    "        if not isinstance(item, dict):\n",
    "            return False\n",
    "        if \"Name\" not in item or not isinstance(item[\"Name\"], str):\n",
    "            return False\n",
    "        if \"Weight\" not in item or not isinstance(item[\"Weight\"], (int, float)):\n",
    "            return False\n",
    "        if \"Value\" not in item or not isinstance(item[\"Value\"], (int, float)):\n",
    "            return False\n",
    "         \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "    {\n",
      "        \"Name\": \"Gold Bar\",\n",
      "        \"Weight\": 10,\n",
      "        \"Value\": 2500\n",
      "    },\n",
      "    {\n",
      "        \"Name\": \"Wedding Crown\",\n",
      "        \"Weight\": 3,\n",
      "        \"Value\": 2000\n",
      "    },\n",
      "    {\n",
      "        \"Name\": \"First Edition Charizard Card\",\n",
      "        \"Weight\": 1,\n",
      "        \"Value\": 1500\n",
      "    },\n",
      "    {\n",
      "        \"Name\": \"Diamond Necklace\",\n",
      "        \"Weight\": 2,\n",
      "        \"Value\": 1200\n",
      "    },\n",
      "    {\n",
      "        \"Name\": \"PokÃ©ball Collector's Edition\",\n",
      "        \"Weight\": 1,\n",
      "        \"Value\": 600\n",
      "    },\n",
      "    {\n",
      "        \"Name\": \"Gold Chain\",\n",
      "        \"Weight\": 2,\n",
      "        \"Value\": 600\n",
      "    },\n",
      "    {\n",
      "        \"Name\": \"Golden Watch\",\n",
      "        \"Weight\": 1,\n",
      "        \"Value\": 500\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m client \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mget_openai_client()\n\u001b[1;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterrogate_o1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKNAPSACK_O1_CONVERSATION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknapsack_checking_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[1;32mc:\\Users\\paolo\\Desktop\\Symbolic-AI-Vs-LLMs\\utils.py:99\u001b[0m, in \u001b[0;36minterrogate_o1\u001b[1;34m(client, model, conversation, response_checking_schema)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe LLM response does not adhere to the required schema. Retrying (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/5)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:       \n\u001b[1;32m---> 99\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe LLM response does not adhere to the required schema. Aborting.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\paolo\\anaconda3\\envs\\locust\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\paolo\\anaconda3\\envs\\locust\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\paolo\\anaconda3\\envs\\locust\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "client = utils.get_openai_client()\n",
    "response = utils.interrogate_o1(client, \"mini\", KNAPSACK_O1_CONVERSATION, knapsack_checking_schema)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_literature_review2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
